# AI Regulatory Framework Comparison

Welcome! This guide provides a clear, comprehensive comparison of how three major powers are regulating artificial intelligence: the European Union, the United States, and Saudi Arabia. Whether you're a researcher, developer, policymaker, or just curious about AI governance, this resource breaks down complex regulations into understandable insights.

---

## üìä Quick Comparison at a Glance

| Metric | EU AI Act (2024) | US EO 14110 (2023)* | Saudi SDAIA (2023‚Äì25) | Where to Find It | Why This Score? |
|--------|:----------------:|:-------------------:|:---------------------:|------------------|-----------------|
| **Human Oversight** | 5 | 4 | 3 | EU: Art. 14; US: EO ¬ß 4.1(a); Saudi: AI Ethics Principle 3 (Humanity) | The EU requires humans to be directly involved in high-risk AI decisions. The US encouraged this practice but made it voluntary. Saudi Arabia mentions it in their ethics principles but doesn't strictly enforce it. |
| **Transparency** | 4 | 3 | 3 | EU: Art. 50, Art. 13; US: EO ¬ß 8(a); Saudi: AI Ethics Principle 6 (Transparency & Explainability) | The EU demands that companies disclose when you're interacting with AI and explain how high-risk systems work. The US promoted transparency but left companies flexibility in how they implement it. Saudi Arabia encourages openness but hasn't made it legally required. |
| **Accountability** | 5 | 4 | 3 | EU: Art. 26, Art. 71; US: EO ¬ß 10(b); Saudi: AI Ethics Principle 7 (Accountability & Responsibility) | If something goes wrong with AI in the EU, there's a clear legal framework for who's responsible. The US delegated accountability to federal agencies. Saudi Arabia emphasizes moral and ethical responsibility without comprehensive legal enforcement yet. |
| **Privacy Protection** | 5 | 4 | 4 | EU: GDPR + AI Act Art. 10; US: EO ¬ß 9; Saudi: PDPL (2023) + AI Ethics Principle 2 | The EU connects AI rules directly to their strict GDPR privacy laws. The US references existing privacy protections. Saudi Arabia has enacted a comprehensive data protection law that works alongside their AI ethics framework. |
| **Security & Robustness** | 4 | 5 | 4 | EU: Art. 15, Annex IV; US: EO ¬ß 4.1(b) + NIST; Saudi: AI Ethics Principle 5 (Reliability & Safety) | The EU requires mandatory security testing for high-risk systems. The US put strong emphasis on cybersecurity through their NIST standards. Saudi Arabia applies safety standards through their ethics framework. |
| **Risk Management** | 5 | 4 | 4 | EU: Art. 6, Art. 9; US: EO ¬ß 5 + NIST AI RMF; Saudi: AI Adoption Framework ¬ß 3 (Risk Classification) | The EU uses a sophisticated four-tier risk system to categorize AI (from unacceptable to minimal risk). The US introduced the NIST AI Risk Management Framework. Saudi Arabia has developed their own risk classification system in their 2024 framework. |
| **Enforcement Strength** | 5 | 3 | 3 | EU: Art. 99; US: EO ¬ß 10; Saudi: Voluntary compliance + PDPL penalties | The EU has teeth‚Äîcompanies can face fines up to **‚Ç¨35M or 7% of worldwide revenue** for serious violations. The US was limited to administrative actions. Saudi Arabia currently relies more on voluntary compliance with sector-specific enforcement. |
| **Fairness & Bias** | 4 | 4 | 3 | EU: Art. 10, Annex IV(2); US: EO ¬ß 7(c); Saudi: AI Ethics Principle 1 (Integrity & Fairness) | The EU mandates that high-risk AI systems must be tested for bias and discrimination. The US encouraged fairness principles through government guidance. Saudi Arabia addresses fairness in their ethics principles but doesn't require binding tests. |
| **Data Quality** | 4 | 4 | 4 | EU: Art. 10, Annex IV(3); US: NIST AI RMF ¬ß 2.3; Saudi: AI Ethics Principle 2 controls | All three regions recognize that AI is only as good as its training data. They each have standards ensuring datasets are high-quality, relevant, and representative‚Äîthough enforcement methods differ. |
| **Monitoring & Audit** | 4 | 4 | 4 | EU: Art. 72; US: EO ¬ß 8(b) + AI Safety Institute; Saudi: AI Adoption Framework ¬ß 5 (Compliance) | The EU requires companies to continuously monitor high-risk AI and report problems. The US established an AI Safety Institute for testing. Saudi Arabia has set up auditing and compliance mechanisms in their latest framework. |

### What Do These Scores Mean?
- **5** = Comprehensive laws with real consequences for violations
- **4** = Strong framework with clear requirements and guidance
- **3** = Guidance-based approach with limited enforcement
- **2** = Minimal framework or mostly voluntary
- **1** = Little to no regulation in this area

---

## ‚ö†Ô∏è Critical Updates You Should Know

### üá∫üá∏ The US Situation Has Changed
**Important:** On January 20, 2025, the Trump administration rescinded Executive Order 14110, which was the main federal AI policy. This means the legal landscape for AI regulation in the US is now uncertain. 

What remains active:
- NIST (National Institute of Standards and Technology) frameworks may continue
- Some agency-specific regulations persist
- State-level AI laws are emerging to fill the gap

The scores in this comparison reflect the framework under Executive Order 14110, but remember that enforcement and requirements may now be quite different.

### üá™üá∫ EU Penalties: The Real Numbers
Many sources get this wrong, so here are the actual fines under Article 99:
- **Up to ‚Ç¨35 million OR 7% of your company's worldwide annual revenue** (whichever hurts more) for:
  - Using prohibited AI practices
  - Violating general-purpose AI model rules
- **Up to ‚Ç¨15 million OR 3% of worldwide revenue** for:
  - Breaking other AI system rules
  - Lying to authorities or providing incomplete information

### üá∏üá¶ Understanding Saudi Arabia's Approach
Saudi Arabia's SDAIA principles are currently **guidance rather than hard law**. However, they're enforced indirectly through:
- The Personal Data Protection Law (PDPL) - this one has legal teeth, effective since September 2023
- Industry-specific regulators (telecom, healthcare, finance, etc.)
- A voluntary compliance certification system that companies can earn

Think of it as a "carrot and stick" approach‚Äîfollow the principles and get recognized, or face consequences through other laws.

---

## üìö Where to Find the Original Documents

If you want to read the source materials yourself (highly recommended for serious research):

### üá™üá∫ European Union AI Act (2024)
- **Official Legal Text**: [Regulation (EU) 2024/1689 on EUR-Lex](https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ:L_202401689)
- **When Published**: July 12, 2024, in the Official Journal
- **When It Started**: August 1, 2024 (but full implementation happens gradually through 2027)
- **Easier to Navigate**: Try the [AI Act Explorer](https://artificialintelligenceact.eu/ai-act-explorer/) for an interactive version

**Pro tip**: The AI Act Explorer lets you search by keyword and shows connections between articles‚Äîmuch easier than reading a 400+ page legal document!

### üá∫üá∏ US Executive Order 14110 (2023) [Now Rescinded]
- **Official Text**: [Federal Register, Volume 88, Page 75191](https://www.federalregister.gov/documents/2023/11/01/2023-24283/safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence)
- **When Signed**: October 30, 2023
- **When Rescinded**: January 20, 2025 (via Executive Order 14148)
- **What Still Matters**:
  - [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework) - Technical standards that many organizations still follow
  - [OMB Memo M-24-10](https://www.whitehouse.gov/wp-content/uploads/2024/03/M-24-10-Advancing-Governance-Innovation-and-Risk-Management-for-Agency-Use-of-Artificial-Intelligence.pdf) - March 2024 guidance for federal agencies

**Historical note**: Even though it's been rescinded, this executive order represents the most comprehensive federal AI policy the US has had to date.

### üá∏üá¶ Saudi SDAIA AI Framework (2023-2025)
- **AI Ethics Principles**: [SDAIA Principles v1.0 (September 2023)](https://sdaia.gov.sa/en/SDAIA/about/Documents/ai-principles.pdf)
- **Implementation Guide**: [AI Adoption Framework (September 2024)](https://sdaia.gov.sa/en/SDAIA/about/Files/AIAdoptionFramework.pdf)
- **The Law That Backs It**: Personal Data Protection Law (PDPL) - enacted March 2023, in effect since September 2023
- **Official Hub**: [Saudi Data & AI Authority](https://sdaia.gov.sa/en)

**Context**: Saudi Arabia is rapidly developing their AI ecosystem. These documents are updated regularly, so check back for new versions.

---

## üìñ Understanding the Details: Key Provisions Explained

### üá™üá∫ EU AI Act - What Each Article Does

| What It Covers | Article Number | What It Actually Means |
|----------------|----------------|------------------------|
| **Risk Classification** | Art. 6 | How the EU decides if your AI is "unacceptable," "high risk," "limited risk," or "minimal risk" |
| **Banned AI** | Art. 5 | The AI you absolutely cannot use (like social scoring systems or manipulative techniques) |
| **Risk Management** | Art. 9 | If you're building high-risk AI, here's the safety system you must have |
| **Data Requirements** | Art. 10 | Rules about the data you use to train, validate, and test your AI |
| **Documentation** | Art. 11, Annex IV | What records you must keep about how your high-risk AI system works |
| **User Transparency** | Art. 13 | What you must tell people who use your high-risk AI system |
| **Human Oversight** | Art. 14 | Requirements for keeping humans in control (in-the-loop, on-the-loop, or in-command) |
| **Accuracy & Security** | Art. 15 | How robust and secure your AI must be against attacks and errors |
| **Provider Duties** | Art. 16-23 | If you make AI systems, here are all your responsibilities |
| **Deployer Duties** | Art. 26 | If you use AI systems (but didn't make them), here's what you must do |
| **Big AI Models** | Art. 50-56 | Special rules for general-purpose AI (like ChatGPT or Claude) |
| **General Transparency** | Art. 50 | Disclosure requirements for AI providers and users |
| **Ongoing Monitoring** | Art. 72 | You must watch how your AI performs after it's released and report problems |
| **Fines** | Art. 99 | How much trouble you're in if you break the rules |

### üá∫üá∏ US Executive Order 14110 - The Main Sections [Historical Reference]

| Topic | Section Number | What It Addressed |
|-------|----------------|-------------------|
| **Big Picture Policy** | ¬ß 1-3 | The overall vision and principles for responsible AI |
| **Safety First** | ¬ß 4.1 | How to manage AI risks, including "red team" testing and reporting dangerous capabilities |
| **Innovation** | ¬ß 5 | Promoting AI development and competition in the marketplace |
| **Civil Rights** | ¬ß 7 | Preventing AI from discriminating against people |
| **Transparency** | ¬ß 8 | Requirements for disclosing AI use and authenticating AI-generated content |
| **Privacy** | ¬ß 9 | Techniques and frameworks to protect people's privacy |
| **Coordination** | ¬ß 10 | How federal agencies should work together on AI |

**Reality check**: These were policy directions to federal agencies, not laws passed by Congress. Their current status depends on what the new administration does.

### üá∏üá¶ Saudi SDAIA - The Seven Core Principles

| Principle | Focus | What It Means in Practice |
|-----------|-------|---------------------------|
| **1. Integrity and Fairness** | Equal treatment | AI should not discriminate and should provide equal access to everyone |
| **2. Privacy and Security** | Data protection | Strong cybersecurity and respect for confidentiality |
| **3. Humanity** | Human dignity | Keeping humans in charge and respecting human values |
| **4. Social & Environmental Benefits** | Sustainability | AI should contribute to society and not harm the environment |
| **5. Reliability and Safety** | Trustworthiness | AI must be accurate, robust, and safe to use |
| **6. Transparency & Explainability** | Openness | People should understand how AI works and how decisions are made |
| **7. Accountability & Responsibility** | Clear ownership | Someone must be responsible when things go wrong |

### üá∏üá¶ Saudi AI Adoption Framework (2024)

| Section | What It Covers | Details |
|---------|----------------|---------|
| **¬ß 1-2** | Introduction | Why this framework exists and who it applies to |
| **¬ß 3** | Risk Levels | Four categories: unacceptable, high, limited, and minimal risk (similar to EU) |
| **¬ß 4** | Governance | Who's responsible for what in organizations |
| **¬ß 5** | Compliance | How monitoring, audits, and certification work |

---

## üîç How We Scored These Frameworks

We evaluated each regulation across ten critical areas of AI governance. Here's what we looked at:

1. **Human Oversight** - Can humans intervene when AI makes important decisions?
2. **Transparency** - Do people know when they're interacting with AI? Can they understand how it works?
3. **Accountability** - If AI causes harm, who's legally responsible?
4. **Privacy Protection** - How well does the framework protect personal data?
5. **Security & Robustness** - Are there requirements for AI systems to be secure and reliable?
6. **Risk Management** - Is there a systematic way to identify and handle AI risks?
7. **Enforcement Strength** - What happens when someone breaks the rules?
8. **Fairness & Bias** - Are there requirements to test for and prevent discrimination?
9. **Data Quality** - Are there standards for the data used to train AI?
10. **Monitoring & Audit** - Must AI be continuously monitored after deployment?

### Our Scoring Criteria
We considered four key factors:
- **Is it binding?** (mandatory law vs. voluntary guidance)
- **How specific?** (detailed requirements vs. general principles)
- **Real enforcement?** (actual penalties, audits, and oversight vs. recommendations)
- **How broad?** (comprehensive coverage vs. limited scope)

---

## üåç Who Do These Rules Apply To?

### üá™üá∫ EU AI Act: The Long Arm of European Law
- **If you're in the EU**: Applies to anyone developing or using AI systems in EU member states
- **If you're outside the EU**: Still applies if your AI's outputs are used in the EU‚Äîyes, even if your company is in Silicon Valley or Shanghai
- **Timeline**: Started August 2024, but full requirements phase in through August 2027

**Real talk**: The EU AI Act has extraterritorial reach similar to GDPR. If you want to do business with Europe, you need to comply.

### üá∫üá∏ US Framework: It's Complicated
- **What it covered**: Federal government agencies and their contractors
- **Current situation**: Uncertain after the executive order rescission‚Äîwatch for state laws filling the gap
- **What continues**: Technical standards from NIST and some agency-specific regulations

**Bottom line**: US AI regulation is now a patchwork. States like California, Colorado, and New York are developing their own AI laws.

### üá∏üá¶ Saudi Arabia: Building a Framework
- **Scope**: AI systems developed, deployed, or used within Saudi Arabia
- **Enforcement**: Through sector-specific regulators and the Personal Data Protection Law
- **Status**: Actively evolving‚Äîexpect updates and expansions

**Context**: Saudi Arabia is investing heavily in becoming an AI leader in the Middle East. Their framework is being refined based on international best practices.

---
